#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
iOS é™å…åº”ç”¨ RSS è§£æå™¨
ä¼˜åŒ–ç‰ˆ - å‚è€ƒRSSæ ¼å¼ï¼Œå±è”½å¹¿å‘Šå†…å®¹ï¼Œæ•´ç†æ ¼å¼
"""

import feedparser
from bs4 import BeautifulSoup
from datetime import datetime
import re
import html
import sys


def is_ad_content(text, soup, entry_description, entry_title):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºå¹¿å‘Š/æ¨å¹¿æ¡ç›®ï¼ˆå¢å¼ºç‰ˆï¼‰
    å‚è€ƒRSSæ ¼å¼ï¼Œç²¾ç¡®è¯†åˆ«å¹¿å‘Šå†…å®¹
    """
    # å¹¿å‘Šå…³é”®è¯åˆ—è¡¨
    ad_keywords = ["ç¾¤ç»„", "é¢‘é“", "è€é¹°", "æ¨ç‰¹", "çº¢è–¯", "Bluesky", "@o0apps", "æ¨é€é¢‘é“"]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å« App Store é“¾æ¥
    has_app_store_link = "apps.apple.com" in entry_description
    
    # å¦‚æœæ²¡æœ‰ App Store é“¾æ¥ï¼Œå¾ˆå¯èƒ½æ˜¯å¹¿å‘Š
    if not has_app_store_link:
        return True
    
    # æ£€æŸ¥æ ‡é¢˜ï¼šå¦‚æœæ˜¯é¢‘é“æ¨å¹¿æ ‡é¢˜ï¼ˆå¦‚"ğŸ–¼ App Store é™å…åº”ç”¨ 01/10/2026"ï¼‰ï¼Œåˆ™ä¸ºå¹¿å‘Š
    if entry_title:
        title_clean = entry_title.strip()
        # å¦‚æœæ ‡é¢˜æ˜¯æ—¥æœŸæ ¼å¼çš„æ±‡æ€»æ ‡é¢˜ï¼Œåˆ™ä¸ºå¹¿å‘Š
        if (("é™å…åº”ç”¨" in title_clean or "é™å…" in title_clean) and 
            ("ğŸ–¼" in title_clean or "ğŸ“±" in title_clean) and
            re.search(r'\d{2}/\d{2}/\d{4}', title_clean)):  # åŒ…å«æ—¥æœŸæ ¼å¼
            return True
    
    # æå–çº¯æ–‡æœ¬å†…å®¹ï¼ˆå»é™¤HTMLæ ‡ç­¾ã€é“¾æ¥ã€blockquoteï¼‰
    # å…ˆç§»é™¤blockquoteï¼ˆé€šå¸¸æ˜¯App Storeå¼•ç”¨ï¼ŒåŒ…å«æœ‰æ•ˆä¿¡æ¯ï¼‰
    soup_clean = BeautifulSoup(entry_description, 'html.parser')
    for blockquote in soup_clean.find_all('blockquote'):
        blockquote.decompose()  # ç§»é™¤blockquoteï¼Œå› ä¸ºå®ƒæ˜¯App Storeä¿¡æ¯ï¼Œä¸ç®—æ¨å¹¿
    
    pure_text = soup_clean.get_text(separator=" ").strip()
    
    # ç§»é™¤é“¾æ¥æ–‡æœ¬ã€æ ‡ç­¾ã€æ¨å¹¿å†…å®¹
    pure_text = re.sub(r'https?://[^\s]+', '', pure_text)
    pure_text = re.sub(r'@\w+', '', pure_text)
    pure_text = re.sub(r'#\w+', '', pure_text)
    pure_text = re.sub(r'(ç¾¤ç»„|é¢‘é“|è€é¹°|æ¨ç‰¹|çº¢è–¯|Bluesky)[ï¼š:].*', '', pure_text)
    pure_text = re.sub(r'\s+', ' ', pure_text).strip()
    
    # ç»Ÿè®¡å¹¿å‘Šå…³é”®è¯æ•°é‡ï¼ˆåœ¨åŸå§‹æ–‡æœ¬ä¸­ï¼‰
    keyword_count = sum(1 for kw in ad_keywords if kw in entry_description)
    
    # æ£€æŸ¥æ¨å¹¿é“¾æ¥æ•°é‡
    promotion_patterns = [
        r'ç¾¤ç»„[ï¼š:].*?https?://',
        r'é¢‘é“[ï¼š:].*?https?://',
        r'è€é¹°[ï¼š:].*?https?://',
        r'æ¨ç‰¹[ï¼š:].*?https?://',
        r'çº¢è–¯[ï¼š:].*?https?://',
        r'Bluesky[ï¼š:].*?https?://'
    ]
    promotion_links_count = sum(1 for pattern in promotion_patterns if re.search(pattern, entry_description, re.IGNORECASE))
    
    # é€»è¾‘åˆ¤æ–­ï¼š
    # 1. å¦‚æœæœ‰3ä¸ªæˆ–ä»¥ä¸Šæ¨å¹¿é“¾æ¥ï¼Œè§†ä¸ºå¹¿å‘Š
    if promotion_links_count >= 3:
        return True
    
    # 2. å¦‚æœå…³é”®å­—è¿‡å¤šï¼Œè§†ä¸ºå¹¿å‘Š
    if keyword_count >= 3:
        return True
    
    # 3. å¦‚æœçº¯æ–‡æœ¬é•¿åº¦å°äº15ï¼Œå¯èƒ½æ˜¯çº¯æ¨å¹¿
    if len(pure_text) < 15:
        return True
    
    # 4. æ£€æŸ¥æ˜¯å¦åªæœ‰æ¨å¹¿å†…å®¹ï¼Œæ²¡æœ‰å®é™…åº”ç”¨æè¿°
    # ç§»é™¤æ‰€æœ‰HTMLæ ‡ç­¾å’Œé“¾æ¥åï¼Œå¦‚æœå‰©ä½™æ–‡æœ¬å¾ˆå°‘ï¼Œå¯èƒ½æ˜¯å¹¿å‘Š
    if len(pure_text) < 20 and promotion_links_count >= 1:
        return True
    
    return False


def clean_description(soup):
    """
    æ¸…ç†æè¿°å†…å®¹ï¼Œç§»é™¤å¹¿å‘Šå†…å®¹
    å‚è€ƒRSSæ ¼å¼ï¼Œç²¾ç¡®æ¸…ç†æ¨å¹¿å†…å®¹
    1. ç§»é™¤ç¾¤ç»„/é¢‘é“/æ¨ç‰¹ç­‰æ¨å¹¿é“¾æ¥
    2. ä¿ç•™App Storeç›¸å…³ä¿¡æ¯ï¼ˆblockquoteä¸­çš„å†…å®¹é€šå¸¸æ˜¯æœ‰ç”¨çš„ï¼‰
    3. æå–æœ‰æ•ˆçš„åº”ç”¨æè¿°
    """
    # åˆ›å»ºå‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹soup
    soup_clean = BeautifulSoup(str(soup), 'html.parser')
    
    # ç§»é™¤å¹¿å‘Šç›¸å…³çš„é“¾æ¥å’Œæ–‡æœ¬
    ad_keywords = ["ç¾¤ç»„", "é¢‘é“", "è€é¹°", "æ¨ç‰¹", "çº¢è–¯", "Bluesky", "@o0apps", "æ¨é€é¢‘é“"]
    
    for tag in soup_clean.find_all(['a', 'p', 'span']):
        tag_text = tag.get_text().strip()
        # å¦‚æœæ ‡ç­¾æ–‡æœ¬åŒ…å«å¹¿å‘Šå…³é”®è¯ï¼Œç§»é™¤è¯¥æ ‡ç­¾
        if any(keyword in tag_text for keyword in ad_keywords):
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨å¹¿é“¾æ¥ï¼ˆåŒ…å«httpï¼‰
            if 'http' in tag_text.lower() or any(keyword in tag_text for keyword in ["ç¾¤ç»„", "é¢‘é“", "@"]):
                tag.decompose()
    
    # ç§»é™¤æ•´è¡ŒåŒ…å«æ¨å¹¿å†…å®¹çš„æ–‡æœ¬
    for text_node in soup_clean.find_all(string=True):
        parent = text_node.parent
        if parent and parent.name not in ['script', 'style']:
            text_content = text_node.strip()
            # å¦‚æœæ–‡æœ¬åŒ…å«æ¨å¹¿å…³é”®è¯å’Œé“¾æ¥ï¼Œç§»é™¤çˆ¶å…ƒç´ 
            if any(keyword in text_content for keyword in ad_keywords) and 'http' in text_content.lower():
                if parent.name in ['p', 'span', 'div']:
                    parent.decompose()
    
    # æå–æœ‰æ•ˆæ–‡æœ¬ï¼ˆblockquoteä¸­çš„å†…å®¹ä¿ç•™ï¼Œå› ä¸ºå®ƒåŒ…å«App Storeä¿¡æ¯ï¼‰
    clean_text = soup_clean.get_text(separator="\n").strip()
    
    # ç§»é™¤ç©ºè¡Œå’Œå¤šä½™çš„ç©ºç™½
    lines = [line.strip() for line in clean_text.split('\n') if line.strip()]
    
    # è¿‡æ»¤æ‰åªåŒ…å«æ¨å¹¿å†…å®¹çš„è¡Œ
    filtered_lines = []
    for line in lines:
        # å¦‚æœè¡ŒåªåŒ…å«é“¾æ¥æˆ–æ¨å¹¿å†…å®¹ï¼Œè·³è¿‡
        if (re.match(r'^https?://', line) or 
            any(keyword in line for keyword in ad_keywords) or
            line.startswith('#') and len(line) < 20):
            continue
        filtered_lines.append(line)
    
    return filtered_lines


def extract_app_info(entry_description, soup, entry_title=""):
    """
    ä»RSSæ¡ç›®ä¸­æå–åº”ç”¨ä¿¡æ¯
    å‚è€ƒRSSæ ¼å¼ï¼Œç²¾ç¡®æå–ä¿¡æ¯
    è¿”å›: åŒ…å«åº”ç”¨ä¿¡æ¯çš„å­—å…¸
    """
    # 1. æå–æ ‡é¢˜
    # ä¼˜å…ˆä½¿ç”¨entry_titleï¼ˆRSSæ ¼å¼ä¸­çš„titleå­—æ®µï¼‰ï¼Œæ›´å‡†ç¡®
    if entry_title:
        title = entry_title.strip()
    else:
        # å¦‚æœæ²¡æœ‰titleï¼Œä»descriptionç¬¬ä¸€è¡Œæå–
        lines = [line.strip() for line in entry_description.split('\n') if line.strip()]
        title = lines[0] if lines else "Unknown App"
    
    # ç§»é™¤æ ‡é¢˜ä¸­çš„è¡¨æƒ…ç¬¦å·æ ‡è®°ï¼ˆå¦‚ ğŸ–¼ ğŸ“±ï¼‰
    title = re.sub(r'[ğŸ–¼ğŸ“±ğŸ“²]', '', title).strip()
    
    # ç§»é™¤æ ‡é¢˜ä¸­çš„æ—¥æœŸæ ¼å¼ï¼ˆå¦‚ "01/10/2026"ï¼‰
    title = re.sub(r'\d{2}/\d{2}/\d{4}', '', title).strip()
    
    # æ¸…ç†æ ‡é¢˜ï¼ˆç§»é™¤å¯èƒ½çš„å¹¿å‘Šæ ‡è®°ï¼‰
    title = re.sub(r'\s*\[.*?\]\s*', '', title)  # ç§»é™¤æ–¹æ‹¬å·å†…å®¹
    title = re.sub(r'\s*\(.*?\)\s*$', '', title)  # ç§»é™¤å°¾éƒ¨æ‹¬å·
    title = title.strip()
    
    # å¦‚æœæ ‡é¢˜è¿˜æ˜¯åŒ…å«"é™å…åº”ç”¨"ç­‰å…³é”®è¯ï¼Œå¯èƒ½ä¸æ˜¯å…·ä½“åº”ç”¨ï¼Œè¿”å›None
    if "é™å…åº”ç”¨" in title or "é™å…" in title and len(title) < 30:
        return None
    
    # 2. æå–App Storeé“¾æ¥ï¼ˆä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™ï¼‰
    app_link_match = re.search(r'https://apps\.apple\.com/[^\s\)"\']+', entry_description)
    if not app_link_match:
        return None
    app_link = app_link_match.group(0).rstrip(')').rstrip('"').rstrip("'")
    
    # 3. æå–æ ‡ç­¾ç±»å‹
    if "#æœ¬ä½“é™å…" in entry_description:
        tag = "# æœ¬ä½“é™å…"
    elif "#å†…è´­é™å…" in entry_description:
        tag = "# å†…è´­é™å…"
    else:
        tag = "# é™æ—¶å…è´¹"
    
    # 4. æå–å›¾ç‰‡URLï¼ˆä¼˜å…ˆä»blockquoteä¸­çš„å›¾ç‰‡ï¼Œå› ä¸ºè´¨é‡æ›´å¥½ï¼‰
    img_url = ""
    blockquote = soup.find('blockquote')
    if blockquote:
        img_tag = blockquote.find('img')
        if img_tag and img_tag.get('src'):
            img_url = img_tag['src']
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»å…¶ä»–åœ°æ–¹æ‰¾ï¼ˆä½†æ’é™¤å¯èƒ½çš„å°å›¾æ ‡ï¼‰
    if not img_url:
        all_imgs = soup.find_all('img')
        for img_tag in all_imgs:
            if img_tag.get('src'):
                src = img_tag['src']
                # ä¼˜å…ˆé€‰æ‹©è¾ƒå¤§çš„å›¾ç‰‡ï¼ˆé€šå¸¸åº”ç”¨æˆªå›¾æ›´å¤§ï¼‰
                if 'cdn' in src or 'telesco' in src:
                    img_url = src
                    break
                elif not img_url:  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°CDNå›¾ç‰‡ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
                    img_url = src
    
    # 5. æå–æè¿°ï¼ˆä¼˜å…ˆä»ä¸»æ–‡æœ¬æå–ä¸­æ–‡æè¿°ï¼Œæ›´å‡†ç¡®ï¼‰
    desc = ""
    
    # æ–¹æ³•1ï¼šä¼˜å…ˆä»ä¸»æ–‡æœ¬ä¸­æå–ä¸­æ–‡æè¿°ï¼ˆé€šå¸¸æ˜¯ç¬¬äºŒè¡Œï¼Œå¦‚"é€»è¾‘å¡«æ ¼ç›Šæ™ºæ¸¸æˆ"ï¼‰
    # æ ¹æ®RSSæ ¼å¼ï¼Œä¸»æ–‡æœ¬çš„ç¬¬äºŒè¡Œé€šå¸¸æ˜¯åº”ç”¨çš„ä¸­æ–‡æè¿°
    clean_lines = clean_description(soup)
    
    # å…ˆå°è¯•æå–ç¬¬äºŒè¡Œï¼ˆé€šå¸¸æ˜¯åº”ç”¨æè¿°ï¼‰
    if len(clean_lines) >= 2:
        second_line = clean_lines[1].strip()
        # å¦‚æœç¬¬äºŒè¡Œæ˜¯æœ‰æ•ˆçš„æè¿°ï¼ˆä¸æ˜¯é“¾æ¥ã€æ ‡ç­¾ã€æ¨å¹¿å†…å®¹ï¼‰
        if (len(second_line) >= 10 and len(second_line) <= 100 and
            not second_line.startswith('http') and 
            not second_line.startswith('#') and 
            not second_line.startswith('Download') and
            "App Store" not in second_line and
            "apps.apple.com" not in second_line and
            not any(x in second_line for x in ["ç¾¤ç»„", "é¢‘é“", "@", "æ¨é€é¢‘é“", "è¿˜å¯ä»¥å…‘æ¢"])):
            desc = second_line
    
    # å¦‚æœç¬¬äºŒè¡Œä¸æ˜¯æœ‰æ•ˆæè¿°ï¼Œéå†æ‰€æœ‰è¡ŒæŸ¥æ‰¾
    if not desc:
        for i, line in enumerate(clean_lines):
            # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆç¬¬ä¸€è¡Œé€šå¸¸æ˜¯åº”ç”¨åï¼‰
            if i == 0 or line == title or line == entry_title:
                continue
            
            # è¿‡æ»¤æ‰é“¾æ¥ã€æ ‡ç­¾ã€æ¨å¹¿å†…å®¹ã€App Storeä¿¡æ¯
            if (len(line) >= 10 and len(line) <= 100 and
                not line.startswith('http') and 
                not line.startswith('#') and 
                not line.startswith('Download') and
                "App Store" not in line and
                "apps.apple.com" not in line and
                not any(x in line for x in ["ç¾¤ç»„", "é¢‘é“", "@", "æ¨é€é¢‘é“", "ç¾¤ç»„:", "é¢‘é“:", "è€é¹°:", "æ¨ç‰¹:", "çº¢è–¯:", "Bluesky:", "è¿˜å¯ä»¥å…‘æ¢"])):
                desc = line
                break
    
    # æ–¹æ³•2ï¼šå¦‚æœä¸»æ–‡æœ¬æ²¡æœ‰æœ‰æ•ˆæè¿°ï¼Œä»blockquoteä¸­çš„App Storeæè¿°æå–ï¼ˆå¤‡ç”¨ï¼‰
    if not desc and blockquote:
        # blockquoteä¸­é€šå¸¸æœ‰App Storeçš„å®Œæ•´æè¿°ï¼Œæ ¼å¼ç±»ä¼¼ï¼š
        # "Download Nonoverse - Nonogram Puzzles by Bartlomiej Niemtur on the App Store. See screenshots, ratings and reviews, user tips, and more games like Nonoverse -â€¦"
        # æˆ‘ä»¬éœ€è¦æå–åº”ç”¨çš„å®é™…æè¿°ï¼Œè€Œä¸æ˜¯"Download ... on the App Store"
        desc_p = blockquote.find('p')
        if desc_p:
            desc_text = desc_p.get_text().strip()
            # ç§»é™¤"Download ... on the App Store"éƒ¨åˆ†
            desc_text = re.sub(r'Download\s+[^.]*?\s+on\s+the\s+App\s+Store\.?\s*', '', desc_text, flags=re.IGNORECASE)
            desc_text = desc_text.strip()
            
            # å¦‚æœè¿˜æœ‰å†…å®¹ï¼Œæå–ç¬¬ä¸€éƒ¨åˆ†ï¼ˆé€šå¸¸æ˜¯åº”ç”¨æè¿°ï¼‰
            if desc_text:
                # ç§»é™¤"See screenshots, ratings..."ç­‰å¸¸è§åç¼€
                desc_text = re.sub(r'See\s+screenshots.*', '', desc_text, flags=re.IGNORECASE).strip()
                desc_text = re.sub(r'See\s+more.*', '', desc_text, flags=re.IGNORECASE).strip()
                
                # æå–ç¬¬ä¸€ä¸ªæœ‰æ„ä¹‰çš„å¥å­
                sentences = desc_text.split('.')
                for sentence in sentences:
                    sentence = sentence.strip()
                    if len(sentence) > 20 and len(sentence) < 150:  # åˆç†çš„æè¿°é•¿åº¦
                        desc = sentence
                        break
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å¥å­ï¼Œä½¿ç”¨å‰100ä¸ªå­—ç¬¦
                if not desc and len(desc_text) > 30:
                    desc = desc_text[:100].strip()
                    if desc.endswith('â€¦') or desc.endswith('...'):
                        desc = desc[:-1].strip()
        
        # å¦‚æœä»pæ ‡ç­¾æ²¡æå–åˆ°ï¼Œå°è¯•ä»æ•´ä¸ªblockquoteæ–‡æœ¬æå–
        if not desc:
            blockquote_text = blockquote.get_text(separator=" ").strip()
            # ç§»é™¤"App Store"ã€"Download"ç­‰å…³é”®è¯
            blockquote_text = re.sub(r'Download\s+[^.]*?\s+on\s+the\s+App\s+Store\.?\s*', '', blockquote_text, flags=re.IGNORECASE)
            blockquote_text = re.sub(r'App\s+Store', '', blockquote_text, flags=re.IGNORECASE)
            blockquote_text = re.sub(r'\s+', ' ', blockquote_text).strip()
            
            if len(blockquote_text) > 30:
                # æå–ç¬¬ä¸€ä¸ªå¥å­
                sentences = blockquote_text.split('.')
                for sentence in sentences:
                    sentence = sentence.strip()
                    if len(sentence) > 20 and len(sentence) < 150:
                        desc = sentence
                        break
    
    # æ¸…ç†æè¿°ï¼šç§»é™¤å¯èƒ½çš„æ¨å¹¿å†…å®¹å’Œå¤šä½™ç©ºç™½
    if desc:
        desc = re.sub(r'https?://[^\s]+', '', desc)
        desc = re.sub(r'@\w+', '', desc)
        desc = re.sub(r'#\w+', '', desc)
        desc = re.sub(r'(ç¾¤ç»„|é¢‘é“|è€é¹°|æ¨ç‰¹|çº¢è–¯|Bluesky)[ï¼š:].*', '', desc)
        desc = re.sub(r'Download\s+.*?App\s+Store', '', desc, flags=re.IGNORECASE)
        desc = re.sub(r'See\s+(screenshots|more).*', '', desc, flags=re.IGNORECASE)
        desc = re.sub(r'\s+', ' ', desc).strip()
        
        # å¦‚æœæè¿°å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯æ— æ•ˆå†…å®¹
        if len(desc) < 10:
            desc = ""
    
    # 6. æå–å…‘æ¢ç ï¼ˆå¦‚æœæœ‰ï¼Œæ ¼å¼ï¼š/redeem/?ctx=offercodes&id=...&code=REDOLIFETIMEFREEDECEMBERï¼‰
    redeem_code = None
    redeem_match = re.search(r'/redeem/.*?code=([A-Z0-9-]+)', entry_description, re.IGNORECASE)
    if redeem_match:
        redeem_code = redeem_match.group(1)
        # æ¸…ç†å…‘æ¢ç ï¼ˆç§»é™¤å¯èƒ½çš„å¼•å·æˆ–ç‰¹æ®Šå­—ç¬¦ï¼‰
        redeem_code = redeem_code.rstrip('"').rstrip("'").rstrip(')').strip()
    
    # éªŒè¯å¿…è¦ä¿¡æ¯
    if not title or len(title) < 2:
        return None
    
    return {
        'title': title,
        'description': desc if desc else "",
        'image_url': img_url,
        'app_link': app_link,
        'tag': tag,
        'redeem_code': redeem_code
    }


def format_date(date_str):
    """æ ¼å¼åŒ–æ—¥æœŸ"""
    try:
        dt = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z")
        return dt.strftime("%Yå¹´%mæœˆ%dæ—¥")
    except:
        try:
            dt = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %z")
            return dt.strftime("%Yå¹´%mæœˆ%dæ—¥")
        except:
            return date_str


def generate_html_output(apps_data, current_date_str, return_html=False):
    """
    ç”ŸæˆHTMLè¾“å‡ºï¼ˆä¼˜åŒ–æ ¼å¼ï¼Œå‚è€ƒRSSç»“æ„ï¼‰
    
    Args:
        apps_data: åº”ç”¨æ•°æ®åˆ—è¡¨
        current_date_str: å½“å‰æ—¥æœŸå­—ç¬¦ä¸²
        return_html: å¦‚æœä¸ºTrueï¼Œè¿”å›HTMLå­—ç¬¦ä¸²ï¼›å¦‚æœä¸ºFalseï¼Œæ‰“å°HTML
    
    Returns:
        å¦‚æœreturn_html=Trueï¼Œè¿”å›HTMLå­—ç¬¦ä¸²ï¼›å¦åˆ™è¿”å›None
    """
    # CSSæ ·å¼ï¼ˆæ·±è‰²æ¨¡å¼ä¼˜åŒ–ï¼‰
    style_block = """<style>
    :root {
        --gbt-accent: #ff9d00;
        --gbt-accent-hover: #ffb136;
        --gbt-bg: #1c2129;
        --gbt-card: #1c2129;
        --gbt-text: #e2e8f0;
        --gbt-sub: #8492a6;
        --gbt-border: #2d323d;
    }
    
    .gbt-resource-wrapper {
        font-family: -apple-system, "PingFang SC", BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
        padding: 15px;
        max-width: 1000px;
        margin: 0 auto;
    }
    
    .gbt-header {
        text-align: center;
        margin: 25px 0 30px;
        color: #000 !important;
        font-size: 24px;
        font-weight: 900;
        line-height: 1.3;
    }
    
    /* æ·±è‰²æ¨¡å¼ä¸‹æ ‡é¢˜é¢œè‰² */
    .dark-theme .gbt-header,
    body.dark-theme .gbt-header,
    html.dark .gbt-header,
    [data-theme="dark"] .gbt-header {
        color: #e2e8f0 !important;
    }
    
    .gbt-resource-card {
        max-width: 880px;
        margin: 0 auto 18px;
        padding: 18px 22px;
        border-radius: 16px;
        background: var(--main-bg-color);
        border: 1px solid var(--border-color);
        display: flex;
        align-items: center;
        gap: 20px;
        transition: all 0.3s ease;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
    }
    
    .dark-theme .gbt-resource-card,
    body.dark-theme .gbt-resource-card,
    html.dark .gbt-resource-card {
        background: var(--gbt-card);
        border-color: var(--gbt-border);
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
    }
    
    .gbt-resource-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);
    }
    
    .dark-theme .gbt-resource-card:hover,
    body.dark-theme .gbt-resource-card:hover {
        box-shadow: 0 12px 35px rgba(0, 0, 0, 0.4);
    }
    
    .gbt-res-preview {
        flex-shrink: 0;
        width: 100px;
        height: 100px;
        border-radius: 18px;
        overflow: hidden;
        border: 2px solid var(--border-color);
        background: #f5f5f5;
    }
    
    .dark-theme .gbt-res-preview,
    body.dark-theme .gbt-res-preview {
        border-color: var(--gbt-border);
        background: #2d323d;
    }
    
    .gbt-res-preview img {
        width: 100%;
        height: 100%;
        object-fit: cover;
        display: block;
    }
    
    .gbt-res-info {
        flex-grow: 1;
        min-width: 0;
    }
    
    .gbt-res-tag {
        display: inline-flex;
        background: rgba(255, 157, 0, 0.12);
        color: var(--gbt-accent);
        padding: 3px 10px;
        font-size: 10px;
        font-weight: 700;
        border-radius: 5px;
        margin-bottom: 8px;
        letter-spacing: 0.3px;
    }
    
    .gbt-res-title {
        font-size: 18px;
        font-weight: 800;
        color: var(--focus-color);
        margin: 0 0 6px 0;
        line-height: 1.35;
    }
    
    .dark-theme .gbt-res-title,
    body.dark-theme .gbt-res-title {
        color: #fff;
    }
    
    .gbt-res-desc {
        font-size: 13px;
        color: var(--muted-2-color);
        line-height: 1.5;
        margin: 0 0 10px 0;
        display: -webkit-box;
        -webkit-line-clamp: 2;
        -webkit-box-orient: vertical;
        overflow: hidden;
    }
    
    .dark-theme .gbt-res-desc,
    body.dark-theme .gbt-res-desc {
        color: var(--gbt-sub);
    }
    
    .gbt-res-footer {
        font-size: 11px;
        color: var(--muted-3-color);
        display: flex;
        align-items: center;
        gap: 10px;
        flex-wrap: wrap;
    }
    
    .dark-theme .gbt-res-footer,
    body.dark-theme .gbt-res-footer {
        color: var(--gbt-sub);
    }
    
    .gbt-redeem-code {
        display: inline-block;
        background: rgba(72, 187, 120, 0.15);
        color: #48bb78;
        padding: 2px 8px;
        border-radius: 5px;
        font-size: 10px;
        font-weight: 600;
        font-family: monospace;
        letter-spacing: 0.3px;
    }
    
    .gbt-publish-date {
        color: var(--muted-3-color);
        font-size: 11px;
    }
    
    .dark-theme .gbt-publish-date {
        color: var(--gbt-sub);
    }
    
    .gbt-download-btn {
        display: inline-flex;
        align-items: center;
        justify-content: center;
        background: var(--gbt-accent);
        color: #fff;
        padding: 10px 22px;
        border-radius: 10px;
        font-weight: 700;
        font-size: 13px;
        text-decoration: none;
        transition: all 0.3s ease;
        white-space: nowrap;
    }
    
    .dark-theme .gbt-download-btn,
    body.dark-theme .gbt-download-btn {
        color: #000;
    }
    
    .gbt-download-btn:hover {
        background: var(--gbt-accent-hover);
        transform: translateY(-1px);
        box-shadow: 0 3px 10px rgba(255, 157, 0, 0.3);
    }
    
    @media (max-width: 650px) {
        .gbt-resource-wrapper {
            padding: 12px;
        }
        
        .gbt-header {
            margin: 20px 0 25px;
            font-size: 20px;
        }
        
        .gbt-resource-card {
            flex-direction: column;
            text-align: center;
            padding: 16px;
            gap: 16px;
        }
        
        .gbt-res-preview {
            width: 90px;
            height: 90px;
        }
        
        .gbt-res-action {
            width: 100%;
        }
        
        .gbt-download-btn {
            width: 100%;
        }
    }
    </style>"""
    
    html_lines = []
    html_lines.append(style_block)
    html_lines.append(f'<div class="gbt-resource-wrapper">')
    html_lines.append(f'<div class="gbt-header">ï£¿ App Store é™å…åº”ç”¨ â€“ {current_date_str}</div>')
    
    for app in apps_data:
        # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
        title = html.escape(app['title'])
        desc = html.escape(app['description']) if app['description'] else "æš‚æ— æè¿°"
        img_url = html.escape(app['image_url']) if app['image_url'] else "https://via.placeholder.com/110x110?text=App"
        app_link = html.escape(app['app_link'])
        tag = html.escape(app['tag'])
        
        # ç”ŸæˆHTMLå¡ç‰‡
        html_lines.append(f'    <div class="gbt-resource-card zib-widget">')
        html_lines.append(f'        <div class="gbt-res-preview"><img src="{img_url}" loading="lazy" alt="{title}" onerror="this.src=\'https://via.placeholder.com/110x110?text=App\'"></div>')
        html_lines.append(f'        <div class="gbt-res-info">')
        html_lines.append(f'            <div class="gbt-res-tag">{tag}</div>')
        html_lines.append(f'            <h3 class="gbt-res-title">{title}</h3>')
        html_lines.append(f'            <p class="gbt-res-desc">{desc}</p>')
        html_lines.append(f'            <div class="gbt-res-footer">')
        if app.get('publish_date'):
            html_lines.append(f'                <span class="gbt-publish-date">å‘å¸ƒæ—¥æœŸï¼š{app["publish_date"]}</span>')
        if app.get('redeem_code'):
            html_lines.append(f'                <span class="gbt-redeem-code">å…‘æ¢ç : {app["redeem_code"]}</span>')
        html_lines.append(f'            </div>')
        html_lines.append(f'        </div>')
        html_lines.append(f'        <div class="gbt-res-action"><a href="{app_link}" target="_blank" rel="noopener" class="gbt-download-btn">ç«‹å³è·å–</a></div>')
        html_lines.append(f'    </div>')
    
    html_lines.append('</div>')
    
    # æ·»åŠ WordPresså—æ³¨é‡Šï¼ˆæŒ‰ç…§å‚è€ƒæ ¼å¼ iosæ ¼å¼.htmlï¼‰
    # æ ¼å¼ï¼š<!-- wp:html --> ... <!-- /wp:html --> ç„¶å <!-- wp:paragraph --><p></p><!-- /wp:paragraph -->
    wp_html = '<!-- wp:html -->\n' + '\n'.join(html_lines) + '\n<!-- /wp:html -->\n\n<!-- wp:paragraph -->\n<p></p>\n<!-- /wp:paragraph -->'
    
    if return_html:
        return wp_html
    else:
        print(wp_html)
        return None


def get_app_limit_free(return_data=False):
    """
    ä¸»å‡½æ•°ï¼šè·å–å¹¶å¤„ç†é™å…åº”ç”¨ä¿¡æ¯
    
    Args:
        return_data: å¦‚æœä¸ºTrueï¼Œè¿”å›(html_content, title, apps_data)ï¼›å¦‚æœä¸ºFalseï¼Œæ‰“å°HTML
    
    Returns:
        å¦‚æœreturn_data=Trueï¼Œè¿”å›(html_content, title, apps_data)å…ƒç»„ï¼š
            - html_content: ç”Ÿæˆçš„HTMLå†…å®¹
            - title: æ–‡ç« æ ‡é¢˜ï¼ˆä¾‹å¦‚ï¼š"App Store é™å…åº”ç”¨ â€“ 2026å¹´01æœˆ10æ—¥"ï¼‰
            - apps_data: åº”ç”¨æ•°æ®åˆ—è¡¨
        å¦‚æœreturn_data=Falseï¼Œè¿”å›None
    """
    rss_url = "https://rsshub.rssforever.com/telegram/channel/ooapps"
    
    try:
        feed = feedparser.parse(rss_url)
    except Exception as e:
        error_msg = f"é”™è¯¯ï¼šæ— æ³•è·å–RSSæº - {str(e)}"
        if return_data:
            return (f"<p style='color: red; padding: 20px;'>{error_msg}</p>", None, [])
        else:
            print(f"<p style='color: red; padding: 20px;'>{error_msg}</p>", file=sys.stderr)
            sys.exit(1)
    
    if not feed.entries:
        error_msg = "<p style='padding: 20px;'>æš‚æ— åº”ç”¨ä¿¡æ¯</p>"
        if return_data:
            return (error_msg, None, [])
        else:
            print(error_msg)
            return None
    
    current_date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    apps_data = []
    
    for entry in feed.entries:
        # 1. åŸºæœ¬è¿‡æ»¤ï¼šå¿…é¡»æœ‰ App Store é“¾æ¥
        if "apps.apple.com" not in entry.description:
            continue
        
        # 2. è·å–entryçš„titleï¼ˆRSSæ ¼å¼ä¸­çš„titleå­—æ®µæ›´å‡†ç¡®ï¼‰
        entry_title = entry.get('title', '').strip() if hasattr(entry, 'title') else ""
        
        # 3. è§£æHTMLå†…å®¹
        soup = BeautifulSoup(entry.description, 'html.parser')
        raw_text = soup.get_text(separator="\n")
        
        # 4. å¹¿å‘Šå†…å®¹è¿‡æ»¤ï¼šæ’é™¤çº¯é¢‘é“æ¨å¹¿æ¡ç›®ï¼ˆä½¿ç”¨entry_titleåˆ¤æ–­æ›´å‡†ç¡®ï¼‰
        if is_ad_content(raw_text, soup, entry.description, entry_title):
            continue
        
        # 5. æå–åº”ç”¨ä¿¡æ¯ï¼ˆä¼ å…¥entry_titleä»¥ä¾¿æ›´å‡†ç¡®æå–ï¼‰
        app_info = extract_app_info(entry.description, soup, entry_title)
        if not app_info:
            continue
        
        # 6. éªŒè¯å¿…è¦ä¿¡æ¯ï¼ˆå¿…é¡»æœ‰æ ‡é¢˜å’Œé“¾æ¥ï¼‰
        if not app_info['title'] or not app_info['app_link']:
            continue
        
        # 7. å¦‚æœæè¿°ä¸ºç©ºæˆ–å¤ªçŸ­ï¼Œè·³è¿‡ï¼ˆå¯èƒ½æ˜¯å¹¿å‘Šï¼‰
        if not app_info['description'] or len(app_info['description']) < 10:
            continue
        
        # 8. å†æ¬¡éªŒè¯ï¼šæ ‡é¢˜ä¸èƒ½åªæ˜¯"é™å…åº”ç”¨"ç­‰é€šç”¨è¯
        if app_info['title'] in ["é™å…åº”ç”¨", "App Store é™å…åº”ç”¨", "é™æ—¶å…è´¹"] or len(app_info['title']) < 3:
            continue
        
        # 9. æ·»åŠ å‘å¸ƒæ—¥æœŸ
        try:
            if hasattr(entry, 'published') and entry.published:
                app_info['publish_date'] = format_date(entry.published)
            elif hasattr(entry, 'published_parsed') and entry.published_parsed:
                app_info['publish_date'] = datetime(*entry.published_parsed[:6]).strftime("%Yå¹´%mæœˆ%dæ—¥")
            else:
                app_info['publish_date'] = current_date_str
        except Exception as e:
            app_info['publish_date'] = current_date_str
        
        apps_data.append(app_info)
    
    # 10. ç”Ÿæˆæ ‡é¢˜ï¼ˆä½¿ç”¨é•¿ç ´æŠ˜å· â€“ï¼‰
    article_title = f"ï£¿ App Store é™å…åº”ç”¨ â€“ {current_date_str}"
    
    # 11. ç”ŸæˆHTMLè¾“å‡º
    if apps_data:
        if return_data:
            html_content = generate_html_output(apps_data, current_date_str, return_html=True)
            return (html_content, article_title, apps_data)
        else:
            generate_html_output(apps_data, current_date_str, return_html=False)
            return None
    else:
        error_msg = "<p style='padding: 20px;'>ä»Šæ—¥æš‚æ— é™å…åº”ç”¨</p>"
        if return_data:
            return (error_msg, article_title, [])
        else:
            print(error_msg)
            return None


if __name__ == "__main__":
    get_app_limit_free()
